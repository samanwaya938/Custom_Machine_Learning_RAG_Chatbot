{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_loader(path):\n",
    "  loader = DirectoryLoader(\n",
    "    path, glob=\"*.pdf\", loader_cls=PyPDFLoader\n",
    "  )\n",
    "  documents = loader.load()\n",
    "  return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_docs = file_loader(r'Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunking_data(data):\n",
    "  split_data = RecursiveCharacterTextSplitter(chunk_size= 500, chunk_overlap = 50)\n",
    "  chunk_data = split_data.split_documents(data)\n",
    "  return chunk_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2120"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_data = chunking_data(extracted_docs)\n",
    "len(chunk_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = get_embedding()\n",
    "# len(embedding.embed_query(\"samanwaya ghosh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding.embed_query(\"samanwaya ghosh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import ServerlessSpec\n",
    "from pinecone.grpc import PineconeGRPC as pinecone\n",
    "\n",
    "pc = pinecone(PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"mlragchatbot\"\n",
    "\n",
    "pc.create_index(name=index_name,\n",
    "                dimension=384,\n",
    "                metric=\"cosine\",\n",
    "                spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data = PineconeVectorStore.from_documents(\n",
    "    documents=chunk_data, \n",
    "    embedding=embedding, \n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x28342e4d0d0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = PineconeVectorStore.from_existing_index(embedding=embedding, index_name=index_name)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='fdc44d8e-b701-4712-a2cc-c89a96397242', metadata={'page': 17.0, 'page_label': '18', 'source': 'Data\\\\100-Machine-Learning-Interview-Questions-and-Answers.pdf'}, page_content='75. Explain The Types Of Supervised Learning?\\nSupervised learning is of two types, namely,\\n1. Regression: It is a kind of Supervised Learning that learns from the given  LabelledDatasets, and then it is able to predict the continuous-valued output for the new data thatis given to the algorithm. It is used in cases where an output requirement is a numberlike money or height etc. Some popular Supervised Learning algorithms are LinearRegression, Logistic Regression.'),\n",
       " Document(id='1dd2cb51-995d-4a49-a07a-229c9e43b94f', metadata={'page': 11.0, 'page_label': '12', 'source': 'Data\\\\Hands-On-Machine-Learning-new (1).pdf'}, page_content='Figure 1-5. A labeled training set for supervised learning (e.g., spam classifica-\\ntion) 8 | Chapter 1: The Machine Learning Landscape\\nA typical supervised learning task is classification. The spam filter is a good\\nexample of this: it is trained with many example emails along with their class\\n(spam or ham), and it must learn how to classify new emails. Another typical\\ntask is to predict a target numeric value, such as the price of a car, given a set of'),\n",
       " Document(id='a5452fa8-1ec3-45fb-8ac9-ea42a8c182f8', metadata={'page': 13.0, 'page_label': '14', 'source': 'Data\\\\100-Machine-Learning-Interview-Questions-and-Answers.pdf'}, page_content='59. Explain The Term Semi-Supervised Machine Learning?\\nSemi-supervised learning is defined as an approach to machine learning that combines a lessamount of labeled data with a huge amount of unlabeled data during the training process. It fallsbetween unsupervised learning and supervised learning.\\n60. Can You Tell Us The Applications Of Supervised Machine Learning In Modern Businesses?\\n1. Healthcare Diagnosis\\n2. Fraud detection\\n3. Email spam detection\\n4. Sentimental analysis')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriver = docs.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "output = retriver.invoke(\"What is Supervised Machine Learning\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GROQ_API_KEY= os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
    "llm = ChatGroq(temperature=0.6, max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "\"You are an expert Data Scientist assistat of qestion-answering tasks.\"\n",
    "\"Use the following pieces of retrieved context to answer \"\n",
    "\"the question. If you don't find any related context then say that you \"\n",
    "\"don't know. Do not give any halusinating answer of this. Use the three sentece maximum and keep the \"\n",
    "\"answer concise.\"\n",
    "\"\\n\\n\"\n",
    "\"{context}\"\n",
    " )\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", system_prompt),\n",
    "  (\"user\", \"{input}\" )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TensorFlow is a machine learning library offering GPU support, distributed computing, and a just-in-time compiler for optimization. It is used in various domains such as natural language processing, recommender systems, and time series forecasting. It provides a NumPy-like core. TensorFlow includes both clustering algorithms and threshold logic units for classification or regression tasks.'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff_chain =create_stuff_documents_chain(llm, chat_prompt)\n",
    "retriver_chain = create_retrieval_chain(retriver, stuff_chain)\n",
    "question = \"What is Tesorflow?\"\n",
    "response_dict = retriver_chain.invoke({\"input\" : question})\n",
    "# response = response_dict[\"answer\"] if isinstance(response_dict, dict) else str(response_dict)\n",
    "response = response_dict['answer']\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "chat_history = []\n",
    "chat_history.extend([\n",
    "  HumanMessage(content=question),\n",
    "  AIMessage(content=response)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is Tesorflow?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='TensorFlow is a machine learning library offering GPU support, distributed computing, and a just-in-time compiler for optimization. It is used in various domains such as natural language processing, recommender systems, and time series forecasting. It provides a NumPy-like core. TensorFlow includes both clustering algorithms and threshold logic units for classification or regression tasks.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "contextualize_system_prompt = (\n",
    "  \"Given a chat history and latest user question \"\n",
    "  \"which might reference context in the chat history, \"\n",
    "  \"formulates a standalone question which can be understood \"\n",
    "  \"without the chat history. Do not answer the question, \"\n",
    "  \"just reformulate it if needed otherwise retuen as it is\"\n",
    ")\n",
    "\n",
    "contextualize_prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", contextualize_system_prompt),\n",
    "  MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "  (\"user\", \"{input}\"),\n",
    "  (\"system\", \"Context: {context}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "\n",
    "create_history_retrieve_chain = create_history_aware_retriever(llm, retriver, contextualize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get started with TensorFlow, you can begin by learning the fundamentals of machine learning and deep learning models such as:\n",
      "\n",
      "1. Linear regression\n",
      "2. Logistic regression\n",
      "3. Neural networks\n",
      "4. Convolutional Neural Networks (CNNs)\n",
      "5. Recurrent Neural Networks (RNNs)\n",
      "6. Long Short-Term Memory (LSTM) networks\n",
      "\n",
      "These models cover the basics and are commonly used in various applications. TensorFlow provides production-ready implementations of these models, allowing you to easily apply them to solve real-world problems.\n"
     ]
    }
   ],
   "source": [
    "history_stuff_chain = create_stuff_documents_chain(llm, contextualize_prompt)\n",
    "history_retrieval_chain = create_retrieval_chain(create_history_retrieve_chain, history_stuff_chain)\n",
    "ans = history_retrieval_chain.invoke({\"input\" :\"What is the modele that I need to learn for this?\", \"chat_history\" : chat_history, \"context\": \"\"})\n",
    "print(ans['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlragchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
